/**
 * Ã‡eviri Servisi
 * Hikayeyi hedef dile Ã§evirir (chunk-based stratejisi ile)
 */

import logger from '@/lib/logger';
import { OpenAIError } from '@/lib/errors';
import { retryOpenAI } from './retry.service';
import { 
  createCompletion,
  parseJSONResponse,
  chunkByTokenLimit,
  estimateTokens,
  type LLMProvider
} from './llm-router.service';

interface PromptScenario {
  translationSystemPrompt: string;
  translationUserPrompt: string;
  titleTranslationSystemPrompt?: string;
  titleTranslationUserPrompt?: string;
}

interface TranslationOptions {
  content: string;
  title: string;
  sourceLang: string;
  targetLang: string;
  model: string;
  provider?: LLMProvider;
  promptScenario?: PromptScenario | null;
}

interface TranslationResult {
  title: string;
  content: string;
  originalLength: number;
  translatedLength: number;
  chunksUsed: number;
  totalTokens: number;
}

/**
 * VarsayÄ±lan baÅŸlÄ±k Ã§evirisi promptlarÄ±
 */
const DEFAULT_TITLE_TRANSLATION_SYSTEM_PROMPT = `Sen profesyonel bir Ã§evirmensin. Hikaye baÅŸlÄ±klarÄ±nÄ± Ã§eviriyorsun.

KURALLAR:
1. BaÅŸlÄ±ÄŸÄ±n anlamÄ±nÄ± ve duygusunu koru
2. Hedef dilde doÄŸal ve Ã§ekici olsun
3. UzunluÄŸu benzer tut
4. Sadece Ã§evrilmiÅŸ baÅŸlÄ±ÄŸÄ± dÃ¶ndÃ¼r (ek aÃ§Ä±klama yok)

Kaynak Dil: {{SOURCE_LANG}}
Hedef Dil: {{TARGET_LANGUAGE}}`;

const DEFAULT_TITLE_TRANSLATION_USER_PROMPT = `BaÅŸlÄ±k: "{{TITLE}}"`;

/**
 * Hikaye baÅŸlÄ±ÄŸÄ±nÄ± Ã§evirir
 */
async function translateTitle(
  title: string,
  sourceLang: string,
  targetLang: string,
  model: string,
  provider: LLMProvider = 'openai',
  promptScenario?: PromptScenario | null
): Promise<string> {
  // DeÄŸiÅŸkenler
  const variables: Record<string, string> = {
    SOURCE_LANG: sourceLang,
    TARGET_LANGUAGE: targetLang,
    TITLE: title
  };

  // Prompt ÅŸablonlarÄ±nÄ± al
  const systemPromptTemplate = promptScenario?.titleTranslationSystemPrompt || DEFAULT_TITLE_TRANSLATION_SYSTEM_PROMPT;
  const userPromptTemplate = promptScenario?.titleTranslationUserPrompt || DEFAULT_TITLE_TRANSLATION_USER_PROMPT;

  const systemPrompt = fillPromptTemplate(systemPromptTemplate, variables);
  const userPrompt = fillPromptTemplate(userPromptTemplate, variables);

  const response = await retryOpenAI(
    () => createCompletion({
      provider,
      model,
      systemPrompt,
      messages: [
        { role: 'user', content: userPrompt }
      ],
      temperature: 0.5
    }),
    'BaÅŸlÄ±k Ã§evirisi'
  );

  return response.trim().replace(/^["']|["']$/g, ''); // TÄ±rnaklarÄ± kaldÄ±r
}

/**
 * VarsayÄ±lan Ã§eviri system prompt'u
 */
const DEFAULT_TRANSLATION_SYSTEM_PROMPT = `Sen profesyonel bir edebi Ã§evirmensin. Hikayeleri hedef dile BÄ°REBÄ°R Ã§eviriyorsun.

ğŸ¯ KRÄ°TÄ°K HEDEF - KARAKTER SAYISI KONTROLÃœ:
- Ã‡eviri orijinalin EN AZ %95'i ve EN FAZLA %105'i olmalÄ±
- SADECE %5 fark toleransÄ± var!
- Bu hedefe ulaÅŸmak iÃ§in her kelimeyi dikkatle Ã§evir

â›” YASAK - ASLA YAPMA (YAPAN MODELÄ° SÄ°LERÄ°Z):
- âŒ ASLA iÃ§eriÄŸi KISALTMA veya Ã–ZETLEME
- âŒ ASLA paragraf, cÃ¼mle veya kelime ATLAMA
- âŒ ASLA sahne, olay veya diyalog Ã‡IKARMA
- âŒ ASLA hikayeyi deÄŸiÅŸtirme veya yeniden yazma
- âŒ ASLA "..." ile kÄ±saltma yapma
- âŒ ASLA "devamÄ±..." gibi ifadeler kullanma
- âŒ ASLA gereksiz aÃ§Ä±klama veya ekleme yapma

âœ… ZORUNLU KURALLAR:
1. HER PARAGRAF, HER CÃœMLE, HER KELÄ°ME eksiksiz Ã§evrilmeli
2. Paragraf sayÄ±sÄ± AYNI kalmalÄ±
3. Karakter ve yer isimleri AYNEN KALSIN (adaptasyonda deÄŸiÅŸecek)
4. SADECE Ã§evrilmiÅŸ metni dÃ¶ndÃ¼r

{{VARIABLES}}`;

const DEFAULT_TRANSLATION_USER_PROMPT = `Ã‡EVÄ°R (KISALTMADAN!):

{{CONTENT}}`;

/**
 * Prompt ÅŸablonunu deÄŸiÅŸkenlerle doldurur
 */
function fillPromptTemplate(
  template: string,
  variables: Record<string, string>
): string {
  let result = template;
  for (const [key, value] of Object.entries(variables)) {
    result = result.replace(new RegExp(`\\{\\{${key}\\}\\}`, 'g'), value);
  }
  return result;
}

/**
 * Tek bir metin parÃ§asÄ±nÄ± Ã§evirir
 */
async function translateChunk(
  chunk: string,
  sourceLang: string,
  targetLang: string,
  model: string,
  chunkIndex: number,
  totalChunks: number,
  previousContext?: string,
  provider: LLMProvider = 'openai',
  promptScenario?: PromptScenario | null
): Promise<string> {
  const originalLength = chunk.length;
  const MIN_LENGTH_RATIO = 0.95; // Ã‡eviri en az orijinalin %95'i olmalÄ± (max %5 kÄ±salma)
  const MAX_LENGTH_RATIO = 1.05; // Ã‡eviri en fazla orijinalin %105'i olmalÄ± (max %5 uzama)
  const MAX_RETRIES = 3;

  // DeÄŸiÅŸkenler
  const minChars = Math.round(originalLength * MIN_LENGTH_RATIO);
  const maxChars = Math.round(originalLength * MAX_LENGTH_RATIO);
  const variables: Record<string, string> = {
    VARIABLES: `Kaynak Dil: ${sourceLang}
Hedef Dil: ${targetLang}
Orijinal metin: ${originalLength} karakter

ğŸ¯ KARAKTER SAYISI HEDEFÄ° (KRÄ°TÄ°K!):
- Minimum: ${minChars} karakter (%95)
- Maksimum: ${maxChars} karakter (%105)
- Tolerans: SADECE %5 fark kabul edilir!

${previousContext ? `[BaÄŸlam: ...${previousContext}]` : ''}
ParÃ§a: ${chunkIndex + 1}/${totalChunks}`,
    CONTENT: chunk,
    SOURCE_LANG: sourceLang,
    TARGET_LANG: targetLang
  };

  // Prompt ÅŸablonlarÄ±nÄ± al (senaryo varsa kullan, yoksa varsayÄ±lan)
  const systemPromptTemplate = promptScenario?.translationSystemPrompt || DEFAULT_TRANSLATION_SYSTEM_PROMPT;
  const userPromptTemplate = promptScenario?.translationUserPrompt || DEFAULT_TRANSLATION_USER_PROMPT;

  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
    const systemPrompt = fillPromptTemplate(systemPromptTemplate, variables);

    const userPrompt = fillPromptTemplate(userPromptTemplate, variables);
    
    const response = await retryOpenAI(
      () => createCompletion({
        provider,
        model,
        systemPrompt,
        messages: [
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3
      }),
      `Chunk ${chunkIndex + 1}/${totalChunks} Ã§evirisi (Deneme ${attempt})`
    );

    const translatedLength = response.length;
    const ratio = translatedLength / originalLength;
    const differencePercent = Math.abs(ratio - 1) * 100;

    // Uzunluk kontrolÃ¼ - %5 tolerans iÃ§inde mi?
    if (ratio >= MIN_LENGTH_RATIO && ratio <= MAX_LENGTH_RATIO) {
      logger.debug(`Chunk ${chunkIndex + 1} Ã§evirildi âœ…`, {
        originalLength,
        translatedLength,
        ratio: Math.round(ratio * 100) + '%',
        difference: `${differencePercent.toFixed(1)}%`
      });
      return response;
    }

    // Ã‡eviri tolerans dÄ±ÅŸÄ±nda - tekrar dene
    const isShort = ratio < MIN_LENGTH_RATIO;
    logger.warn(`âš ï¸ Ã‡eviri ${isShort ? 'Ã§ok kÄ±sa' : 'Ã§ok uzun'}! Tekrar deneniyor (${attempt}/${MAX_RETRIES})`, {
      chunkIndex: chunkIndex + 1,
      originalLength,
      translatedLength,
      ratio: Math.round(ratio * 100) + '%',
      difference: `${differencePercent.toFixed(1)}%`,
      target: `${minChars}-${maxChars} karakter`
    });

    if (attempt === MAX_RETRIES) {
      logger.error(`âŒ Ã‡eviri ${MAX_RETRIES} denemede de %5 tolerans dÄ±ÅŸÄ±nda kaldÄ±! Yine de kullanÄ±lÄ±yor.`, {
        chunkIndex: chunkIndex + 1,
        ratio: Math.round(ratio * 100) + '%',
        difference: `${differencePercent.toFixed(1)}%`
      });
      return response;
    }
  }

  // Fallback (buraya ulaÅŸmamalÄ±)
  throw new OpenAIError(`Chunk ${chunkIndex + 1} Ã§evirilemedi`);
}

/**
 * Tam hikayeyi Ã§evirir (chunk-based)
 */
export async function translateStory(options: TranslationOptions): Promise<TranslationResult> {
  const { content, title, sourceLang, targetLang, model, provider = 'openai', promptScenario } = options;

  logger.info('Hikaye Ã§evirisi baÅŸlatÄ±lÄ±yor', {
    sourceLang,
    targetLang,
    model,
    provider,
    contentLength: content.length,
    estimatedTokens: estimateTokens(content, provider)
  });

  try {
    // 1. BaÅŸlÄ±k Ã§evirisi
    logger.debug('BaÅŸlÄ±k Ã§evriliyor...');
    const translatedTitle = await translateTitle(title, sourceLang, targetLang, model, provider, promptScenario);
    
    logger.info('BaÅŸlÄ±k Ã§evirildi', { 
      original: title, 
      translated: translatedTitle 
    });

    // 2. Ä°Ã§eriÄŸi chunk'lara bÃ¶l
    const chunks = chunkByTokenLimit(content, model, provider, 2000); // 2000 token reserve (Ã§eviri iÃ§in)
    
    logger.info("Ä°Ã§erik chunk'lara bÃ¶lÃ¼ndÃ¼", {
      totalChunks: chunks.length,
      avgChunkSize: Math.round(content.length / chunks.length)
    });

    // 3. Her chunk'Ä± Ã§evir (sÄ±ralÄ± olarak - tutarlÄ±lÄ±k iÃ§in)
    const translatedChunks: string[] = [];
    let totalTokens = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      logger.debug(`Chunk ${i + 1}/${chunks.length} Ã§evriliyor...`, {
        chunkLength: chunk.length,
        chunkTokens: estimateTokens(chunk, provider)
      });

      // Son chunk'Ä±n son 200 karakterini context olarak kullan (tutarlÄ±lÄ±k iÃ§in)
      const previousContext = i > 0 
        ? translatedChunks[i - 1].slice(-200) 
        : undefined;

      const translatedChunk = await translateChunk(
        chunk,
        sourceLang,
        targetLang,
        model,
        i,
        chunks.length,
        previousContext,
        provider,
        promptScenario
      );

      translatedChunks.push(translatedChunk);
      totalTokens += estimateTokens(chunk, provider) + estimateTokens(translatedChunk, provider);

      logger.debug(`Chunk ${i + 1}/${chunks.length} tamamlandÄ±`);
    }

    // 4. Chunk'larÄ± birleÅŸtir
    const translatedContent = translatedChunks.join('\n\n');

    // 5. Uzunluk kontrolÃ¼ - %5 tolerans iÃ§inde mi?
    const lengthRatio = translatedContent.length / content.length;
    const differencePercent = Math.abs(lengthRatio - 1) * 100;
    
    if (differencePercent > 5) {
      const isShort = lengthRatio < 1;
      logger.warn(`âš ï¸ UYARI: Ã‡eviri ${isShort ? 'kÄ±sa' : 'uzun'}! %5 tolerans aÅŸÄ±ldÄ±.`, {
        originalLength: content.length,
        translatedLength: translatedContent.length,
        ratio: Math.round(lengthRatio * 100) + '%',
        difference: `${differencePercent.toFixed(1)}%`,
        target: `${Math.round(content.length * 0.95)}-${Math.round(content.length * 1.05)} karakter`
      });
    } else {
      logger.info('âœ… Ã‡eviri uzunluÄŸu %5 tolerans iÃ§inde', {
        originalLength: content.length,
        translatedLength: translatedContent.length,
        ratio: Math.round(lengthRatio * 100) + '%',
        difference: `${differencePercent.toFixed(1)}%`
      });
    }

    logger.info('Hikaye Ã§evirisi tamamlandÄ±', {
      originalLength: content.length,
      translatedLength: translatedContent.length,
      lengthRatio: Math.round(lengthRatio * 100) + '%',
      chunksUsed: chunks.length,
      totalTokens
    });

    return {
      title: translatedTitle,
      content: translatedContent,
      originalLength: content.length,
      translatedLength: translatedContent.length,
      chunksUsed: chunks.length,
      totalTokens
    };

  } catch (error) {
    logger.error('Ã‡eviri hatasÄ±', {
      error: error instanceof Error ? error.message : 'Bilinmeyen hata',
      sourceLang,
      targetLang,
      contentLength: content.length
    });

    throw new OpenAIError(
      `Ã‡eviri baÅŸarÄ±sÄ±z (${sourceLang} -> ${targetLang}): ${error instanceof Error ? error.message : 'Bilinmeyen hata'}`
    );
  }
}

/**
 * HÄ±zlÄ± Ã§eviri (kÄ±sa metinler iÃ§in - chunk'sÄ±z)
 */
export async function translateText(
  text: string,
  sourceLang: string,
  targetLang: string,
  model: string = 'gpt-4o-mini',
  provider: LLMProvider = 'openai'
): Promise<string> {
  if (estimateTokens(text, provider) > 8000) {
    throw new OpenAIError('Metin Ã§ok uzun, translateStory() kullanÄ±n');
  }

  return await translateChunk(text, sourceLang, targetLang, model, 0, 1, undefined, provider);
}

